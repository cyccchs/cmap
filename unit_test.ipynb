{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.zeros([8,2], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x_min': 522, 'y_min': 138, 'x_max': 591, 'y_max': 393},\n",
       " {'x_min': 943, 'y_min': 466, 'x_max': 1013, 'y_max': 720}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "def bboxParser(fileName):\n",
    "    root = ET.parse(fileName + '.xml')\n",
    "    coordinates = []\n",
    "    for obj in root.iter('HRSC_Object'):\n",
    "        coordinate = {}\n",
    "        coordinate['x_min'] = int(obj.find('box_xmin').text)\n",
    "        coordinate['y_min'] = int(obj.find('box_ymin').text)\n",
    "        coordinate['x_max'] = int(obj.find('box_xmax').text)\n",
    "        coordinate['y_max'] = int(obj.find('box_ymax').text)\n",
    "        coordinates.append(coordinate)\n",
    "        \n",
    "    return int(root.find('Img_SizeWidth').text), int(root.find('Img_SizeHeight').text), coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "def objectParser(fileName):\n",
    "    try:\n",
    "        root = ET.parse(fileName)\n",
    "        object_num = 0\n",
    "        for obj in root.iter('HRSC_Object'):\n",
    "            object_num = object_num + 1\n",
    "        return object_num\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 0, 1, 1, 1, 0, 1, 4, 3, 0, 1, 1, 5, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 3, 1, 3, 3, 2, 1, 1, 2, 1, 1, 5, 0, 4, 1, 0, 1, 1, 4, 3, 2, 3, 1, 2, 2, 4, 2, 2, 3, 2, 5, 2, 1, 1, 2, 2, 3, 1, 1, 1, 8, 3, 3, 0, 5, 4, 5, 4, 4, 3, 1, 6, 1, 4, 3, 2, 1, 1, 1, 2, 1, 4, 2, 3, 3, 2, 1, 1, 5, 5, 2, 1, 1, 1, 1, 1, 1, 6, 4, 1, 1, 1, 5, 3, 3, 1, 1, 1, 1, 1, 5, 1, 2, 1, 1, 5, 2, 1, 3, 1, 1, 3, 4, 5, 3, 1, 2, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 2, 6, 2, 6, 4, 5, 4, 2, 1, 1, 3, 1, 3, 2, 1, 1, 1, 1, 1, 0, 2, 2, 5, 1, 1, 1, 3, 2, 1, 1, 2, 2, 1, 4, 4, 1, 2, 2, 1, 3, 2, 2, 1, 1, 1, 4, 2, 2, 2, 3, 1, 3, 3, 1, 5, 1, 3, 2, 5, 1, 2, 1, 2, 2, 4, 4, 3, 3, 1, 1, 1, 1, 4, 3, 1, 2, 1, 2, 3, 2, 2, 2, 2, 2, 1, 3, 7, 2, 1, 1, 1, 1, 3, 2, 3, 1, 1, 1, 3, 3, 5, 1, 3, 5, 6, 1, 2, 3, 2, 3, 1, 1, 2, 2, 3, 5, 6, 8, 3, 1, 1, 1, 3, 1, 2, 3, 4, 5, 3, 8, 9, 1, 2, 1, 2, 5, 3, 6, 2, 4, 3, 3, 6, 2, 3, 1, 1, 1, 2, 3, 1, 2, 1, 2, 2, 8, 4, 3, 1, 6, 3, 9, 5, 1, 3, 1, 2, 1, 1, 3, 7, 4, 6, 1, 1, 1, 3, 9, 1, 3, 2, 2, 4, 3, 2, 5, 4, 1, 3, 4, 3, 5, 5, 9, 4, 3, 1, 1, 1, 2, 5, 6, 7, 3, 10, 6, 1, 1, 1, 2, 6, 7, 7, 1, 7, 1, 1, 3, 3, 4, 3, 5, 5, 4, 6, 1, 1, 1, 1, 5, 4, 6, 7, 4, 2, 2, 2, 1, 1, 2, 3, 6, 5, 8, 4, 2, 3, 1, 2, 2, 1, 3, 7, 2, 5, 5, 3, 4, 3, 1, 1, 3, 3, 6, 4, 2, 4, 4, 8, 6, 3, 4, 1, 1, 1, 1, 2, 7, 3, 3, 4, 1, 2, 1, 1, 1, 1, 3, 4, 3, 2, 4, 9, 12, 2, 4, 3, 4, 5, 7, 5, 3, 3, 1, 1, 1, 1, 3, 5, 7, 4, 1, 1, 1, 4, 4, 5, 4, 4, 3, 2, 1, 1, 2, 3, 5, 5, 2, 4, 3, 2, 5, 2, 1, 3, 1, 1, 8, 3, 1, 1, 4, 1, 3, 1, 1, 4, 1, 1, 1, 3, 2, 5, 3, 3, 2, 2, 10, 11, 4, 2, 7, 7, 3, 8, 3, 1, 1, 1, 7, 7, 4, 2, 1, 1, 1, 1, 3, 6, 8, 1, 2, 1, 1, 1, 1, 1, 5, 1, 2, 1, 2, 2, 1, 2, 4, 7, 7, 4, 1, 1, 1, 3, 5, 4, 2, 1, 1, 1, 1, 5, 1, 5, 1, 1, 1, 2, 2, 1, 4, 10, 13, 9, 2, 5, 6, 6, 4, 4, 1, 1, 1, 1, 2, 1, 4, 5, 6, 4, 3, 4, 8, 2, 2, 2, 3, 2, 1, 5, 1, 4, 6, 5, 4, 6, 4, 1, 4, 7, 6, 4, 7, 1, 1, 7, 10, 8, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "object_num_list = []\n",
    "for i in range(1,1681):\n",
    "    name = './dataset/labels/1' + str(i).zfill(8) + '.xml'\n",
    "    object_num = objectParser(name)\n",
    "    if object_num != None:\n",
    "        object_num_list.append(object_num)\n",
    "        \n",
    "print(object_num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(object_num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def weight(shape):\n",
    "    w = torch.empty(shape)\n",
    "    initial = torch.nn.init.trunc_normal_(w)\n",
    "    return initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = weight((3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0562,  0.1950,  0.2111, -0.7356,  0.4723],\n",
       "        [-0.5127,  0.7964,  0.8249, -1.7378,  0.3028],\n",
       "        [ 0.2230, -0.6746, -1.2672, -1.6923, -1.3758]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "max_h = 0\n",
    "max_w = 0\n",
    "for i in range(1,1681):\n",
    "    name = './current_data/AllImages/1' + str(i).zfill(8) + '.bmp'\n",
    "    img = cv.imread(name)\n",
    "    if img is None:\n",
    "        pass\n",
    "    else:\n",
    "        img_h, img_w, ch = img.shape\n",
    "        print(name)\n",
    "        if img_h > max_h:\n",
    "            max_h = img_h\n",
    "        if img_w > max_w:\n",
    "            max_w = img_w\n",
    "print('max_h: %d, max_w: %d' % (max_h, max_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "new_h = 844\n",
    "new_w = 1238\n",
    "for i in range(1,1681):\n",
    "    name = './current_data/AllImages/1' + str(i).zfill(8) + '.bmp'\n",
    "    img = cv.imread(name)\n",
    "    if img is None:\n",
    "        pass\n",
    "    else:\n",
    "        img_h, img_w, ch = img.shape\n",
    "        padding = np.full((new_h,new_w,3),(34,47,32), dtype=np.uint8)\n",
    "        padding[0:img_h, 0:img_w] = img\n",
    "        cv.imwrite('./pad/'+str(i)+'.bmp', padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes labels. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57011/3678519001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dataset/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cmap/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     ):\n\u001b[0;32m--> 310\u001b[0;31m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[1;32m    311\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmap/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    144\u001b[0m                                             target_transform=target_transform)\n\u001b[1;32m    145\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmap/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmap/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes labels. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder('./dataset/',transform=transforms.Compose([transforms.ToTensor()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
